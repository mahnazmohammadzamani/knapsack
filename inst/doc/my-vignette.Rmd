---
title: Slow and Fast solves for the Knapsack Problem
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Slow and Fast solves for the Knapsack Problem}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Introduction
The [Knapsack Problem](https://en.wikipedia.org/wiki/Knapsack_problem)  is a well known problem in Computing. This package, called ["knapsack"](https://github.com/rojanka/knapsack), implements four different solutions for this problem: the first two use brute-force methods - of these, the first makes use only of one processor core, whereas the second uses multiple cores via parallel programming techniques - the remaining two solutions apply dynamic programming and greedy approaches respectively. In each of these cases, the solution is implemented as a function (hereafter "package functions"), as described below.

```{r setup}
library(knapsack)
```
# Package Solutions
## Function implementing a Brute-Force Solution (without Parallelisation)
Given _n_ items to choose from, the __knapsack_brute_force__ function goes over each of the _2^n_ possible ways of filling the knapsack, whilst keeping track of the hitherto most optimal solution, and returns outputs as described above. Our implementation, however, does not allow for _n_ to be any larger than 31; this is because of our reliance on the _intToBits_ function, which requires arguments to be integers, which in turn can be no larger than 2^31 - 1 (2,147,483,647) in _R_.
## 1.1.2 Brute force search

Given its _O(2^n)_ time complexity, this function does not perform optimally in terms of time taken for execution. For n = 16 items and knapsack capacity W = 2000, we can see below the time taken for function execution.

```{r, eval=F}
# Function to get time
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <-16
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )
get_time <- function(i){
  time <- system.time(expr = brute_force_knapsack(x = knapsack_objects[1:16,], W=i))[3]
  return(time)}
# Function to get mean execution time
mean(unlist(lapply(c(10,100,500,1000,1500,2000,3000,4000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 16 objects?
  - Average Code Execution Time: **2.67375 seconds**
  
## 1.1.3 Dynamic Programming
## Function implementing a Dynamic Programming based Solution
The __knapsack_dynamic__ function solves the knapsack problem using dynamic programming, as outlined in several texts (see references). 
This function has time complexity of order _O(n.W)_, where _n_ is the number of items that can potentially be included in the knapsack and _W_ is the knapsack capacity. One can therefore expect faster execution as compared to a single processor Brute Force implementation. For n = 500 items and knapsack capacity W = 2000, we can see below the time taken for function execution.
```{r, eval=F}
# Data Object
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <-500
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )


# Function to get time
get_time <- function(i){
  time <- system.time(expr = knapsack_dynamic(x = knapsack_objects[1:500,], W=i))[3]
  return(time)}
# Function to get mean execution time
mean(unlist(lapply(c(100,500,1000,1500,2000,3000,4000,5000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 500 objects?
  - Average Code Execution Time: **3.33125 seconds**

## 1.1.4 Greedy Heuristics
## Function implementing a Greedy Approach
The function __greedy_knapsack__ uses a [greedy approach](https://en.wikipedia.org/wiki/Greedy_algorithm) which, as cited in the literature we reference below, consists of sorting available items in descending order of their value per unit weight and including in the knapsack as many of the top-most items as it can possibly hold. Although this approach may not provide the most optimal solution to the problem, its solution is guaranteed (as also cited in the literature referenced) to generate knapsack value that is, at worst, half of the maximum value that can possibly be generated with the given objects and knapsack capacity.
This function has time complexity of order _O(n.log(n))_, where _n_ is the number of items that can potentially be included in the knapsack. This follows from the fact that the complexity of the sorting operation overwhelms the sum of complexities of all the other operations in the procedure. One can therefore expect faster execution even in comparison to Dynamic Programming based implementations. For n = 1,000,000 items and knapsack capacity W = 2000, we can see below the time taken for function execution.
```{r, eval=F}
# Data Object
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <-1000000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )

# Function to get time
get_time <- function(i){
  time <- system.time(expr = greedy_knapsack(x = knapsack_objects[1:1000000,], W=i))[3]
  return(time)}

# Function to get mean execution time
mean(unlist(lapply(c(1000,2500,5000,10000,15000,20000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 1000000 objects?
  - Average Code Execution Time: **0.435 seconds**
  
## 1.1.6 Profile your code and optimize your code
### Profiling and optimising the Greedy Approach Function
Profiling using the [profvis](https://rstudio.github.io/profvis/) package helped optimise our __greedy_knapsack__ function. Profiles revealed a bottleneck wherein the input data.frame of knapsack objects was being sorted. Thereafter, we created another version of the greedy function which used sorted row indices in place of the sorted data.frame. This brought in over 2x performance gain.
```{r, eval=F}
# Function to get time
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <-1000000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
)
    
get_time <- function(i){
  time <- system.time(expr = another_greedy_knapsack(x = knapsack_objects[1:1000000,], W=i))[3]
  return(time)}

# Function to get mean execution time
mean(unlist(lapply(c(1000,2500,5000,10000,15000,20000), FUN = get_time)))
```

- **Question:** What performance gain could you get by trying to improving your code?
  - Implemented:
    - **_Code Organization_** : Reduced no. of operations per function, saving time on multiple code block execution.
    - **_Vectorization_** : Replaced loops with Vectorization wherever possible, which reduced code execution time
    - **_Parallelization_** : Added Parallel programming for Windows machine, which boosted execution time for large no. of values in 'brute_force_knapsack' program.
    
## 1.1.7 Parallelize brute force search
## Function implenting a Parallelised version of the Brute-Force Solution
The _knapsack_brute_force_ function described above also takes on an optional argument _'parallel'_ whose value is set to _FALSE_ by default. Forcing it to _TRUE_ however invokes the parallelised version of the above mentioned brute-force solution. If the machine running the function has suitable computing hardware and if there are a sufficiently large number of objects to choose from, then despite the function still having time complexity of order _O(2^n)_, parallelisation will deliver significantly faster execution.
- Set parameter `parallel = TRUE` 

```{r, eval=F}
# Function to get time

set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <-100000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )
get_time <- function(i){
  time <- system.time(expr = brute_force_knapsack_parallel(x = knapsack_objects[1:16,], W=i,parallel = TRUE))[3]
  return(time)}
# Function to get mean execution time
mean(unlist(lapply(c(10,100,500,1000,1500,2000,3000,4000), FUN = get_time)))
```

# 1.2 Profile and improve your existing API package


# Conclusion
Among the multiple solutions we have made available through the ["knapsack"](https://github.com/rojanka/knapsack) package, the brute-force based function, __"knapsack_brute_force"__ is the slowest. Parallelisation improves speed of execution, but the inherent high time complexity of the algorithm, makes it less efficient than the __"knapsack_dynamic"__ function. Dynamic programming brings down algorithm time complexity, but can still take a large amount of time for execution if there a very large number of objects to choose from. In such a case, the function __"another_greedy_knapsack"__ will deliver best performance in terms of speed of execution, but at the cost of some accuracy.

# References
1. [Knapsack Problem - Wikipedia](https://en.wikipedia.org/wiki/Knapsack_problem)
1. [Dynamic Programming Solution - T. Cormen, C. Leiserson, R. Rivest, and C. Stein. (2009) - p317-8](http://mitp-content-server.mit.edu:18180/books/content/sectbyfn?collid=books_pres_0&id=8030&fn=Intro_to_Algo_Selected_Solutions.pdf)
1. [Approximation Algorithms I - MIT OpenCourseWare](https://ocw.mit.edu/courses/sloan-school-of-management/15-083j-integer-programming-and-combinatorial-optimization-fall-2009/lecture-notes/MIT15_083JF09_lec21.pdf)
1. [Greedy Algorithms - Wikipedia](https://en.wikipedia.org/wiki/Greedy_algorithm)
1. [Greedy Algorithms - MIT OpenCourseWare](https://ocw.mit.edu/courses/civil-and-environmental-engineering/1-204-computer-algorithms-in-systems-engineering-spring-2010/lecture-notes/MIT1_204S10_lec10.pdf)