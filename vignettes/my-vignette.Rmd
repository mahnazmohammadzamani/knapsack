---
title: "Slow and Fast solves for the Knapsack Problem"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"Slow and Fast solves for the Knapsack Problem"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Introduction
The [Knapsack Problem](https://en.wikipedia.org/wiki/Knapsack_problem)  is a well known problem in Computing. This package, called ["knapsack"](https://github.com/rojanka/knapsack), implements four different solutions for this problem: the first two use brute-force methods - of these, the first makes use only of one processor core, whereas the second uses multiple cores via parallel programming techniques - the remaining two solutions apply dynamic programming and greedy approaches respectively. In each of these cases, the solution is implemented as a function (hereafter "package functions"), as described below.

```{r setup}
library(knapsack)
```

## 1.1.2 Brute force search

```{r, eval=F}
# Function to get time
get_time <- function(i){
  time <- system.time(expr = brute_force_knapsack(x = knapsack_objects[1:16,], W=i))[3]
  return(time)}

# Function to get mean execution time
mean(unlist(lapply(c(10,100,1000,10000, 100000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 16 objects?
  - Average Code Execution Time: **2.004 seconds**
  
## 1.1.3 Dynamic Programming

```{r, eval=F}
# Data Object
n <-1000000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )
# Function to get time
get_time <- function(i){
  time <- system.time(expr = knapsack_dynamic(x = knapsack_objects[1:500,], W=i))[3]
  return(time)}

# Function to get mean execution time
mean(unlist(lapply(c(100,500,1000,1500,2000,3000,4000,5000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 500 objects?
  - Average Code Execution Time: **2.65 seconds**

## 1.1.4 Greedy Heuristics

```{r, eval=F}
# Data Object
n <-1000000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )
# Function to get time
get_time <- function(i){
  time <- system.time(expr = greedy_knapsack(x = knapsack_objects[1:1000000,], W=i))[3]
  return(time)}


mean(unlist(lapply(c(1000,2500,5000,10000,15000,20000), FUN = get_time)))

# Function to get mean execution time
mean(unlist(lapply(c(1000,2500,5000,10000,15000,20000), FUN = get_time)))
```

- **Question:** How much time does it takes to run the algorithm for n = 1000000 objects?
  - Average Code Execution Time: **0.34 seconds**
  
## 1.1.6 Profile your code and optimize your code

- **Question:** What performance gain could you get by trying to improving your code?
  - Implemented:
    - **_Code Organization_** : Reduced no. of operations per function, saving time on multiple code block execution.
    - **_Vectorization_** : Replaced loops with Vectorization wherever possible, which reduced code execution time
    - **_Parallelization_** : Added Parallel programming for Windows machine, which boosted execution time for large no. of values in 'brute_force_knapsack' program.
    
## 1.1.7 Parallelize brute force search

- Set parameter `parallel = T` 

```{r, eval=F}
brute_force_knapsack(x = knapsack_objects[1:8,], W = 3500, parallel = T)
brute_force_knapsack(x = knapsack_objects[1:8,], W = 2000, parallel = T)
```

# 1.2 Profile and improve your existing API package

## Solution-1: Add Memoization to reduce API calls overhead

```{r, eval=F}
install.packages("memoise")

library(memoise)

f <- memoise(func)
```
## Solution-2: Chunking

- Limited no. of trials per call to 10,000 only.
# Conclusion
Among the multiple solutions we have made available through the ["knapsack"](https://github.com/rojanka/knapsack) package, the brute-force based function, __"knapsack_brute_force"__ is the slowest. Parallelisation improves speed of execution, but the inherent high time complexity of the algorithm, makes it less efficient than the __"knapsack_dynamic"__ function. Dynamic programming brings down algorithm time complexity, but can still take a large amount of time for execution if there a very large number of objects to choose from. In such a case, the function __"another_greedy_knapsack"__ will deliver best performance in terms of speed of execution, but at the cost of some accuracy.

# References
1. [Knapsack Problem - Wikipedia](https://en.wikipedia.org/wiki/Knapsack_problem)
1. [Dynamic Programming Solution - T. Cormen, C. Leiserson, R. Rivest, and C. Stein. (2009) - p317-8](http://mitp-content-server.mit.edu:18180/books/content/sectbyfn?collid=books_pres_0&id=8030&fn=Intro_to_Algo_Selected_Solutions.pdf)
1. [Approximation Algorithms I - MIT OpenCourseWare](https://ocw.mit.edu/courses/sloan-school-of-management/15-083j-integer-programming-and-combinatorial-optimization-fall-2009/lecture-notes/MIT15_083JF09_lec21.pdf)
1. [Greedy Algorithms - Wikipedia](https://en.wikipedia.org/wiki/Greedy_algorithm)
1. [Greedy Algorithms - MIT OpenCourseWare](https://ocw.mit.edu/courses/civil-and-environmental-engineering/1-204-computer-algorithms-in-systems-engineering-spring-2010/lecture-notes/MIT1_204S10_lec10.pdf)
